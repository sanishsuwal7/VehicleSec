{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pip Installs"
      ],
      "metadata": {
        "id": "8Y8QGIhq-k3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!pip install cleverhans\n",
        "!pip install quantus\n",
        "!pip install captum\n",
        "!pip install ranger-adabelief"
      ],
      "metadata": {
        "id": "ETgLVNWO-oOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "EixHUPJz-srq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "import torch.optim as optim\n",
        "from cleverhans.torch.attacks.projected_gradient_descent import (projected_gradient_descent)\n",
        "\n",
        "import quantus\n",
        "import captum\n",
        "from captum.attr import Saliency, IntegratedGradients, NoiseTunnel\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import copy\n",
        "import gc\n",
        "import math\n",
        "\n",
        "import warnings\n",
        "\n",
        "import os\n",
        "from itertools import chain\n",
        "\n",
        "from collections import Counter\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "0QChV1hu-t6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-4Cw9rkUDei"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run GTSRB/utilities.ipynb\n",
        "%run GTSRB/model_architectures.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "O0Q3RcoyJ-hO",
        "outputId": "74085ffa-4293-4ab6-ba0a-65c0c2991f06"
      },
      "execution_count": null,
      "outputs": [],
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssCDEE5ljhEa"
      },
      "source": [
        "Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWezQnAdoLzP"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "batch_size = 128\n",
        "image_size = (32, 32)\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.4563, 0.4076, 0.3895], std=[0.2298, 0.2144, 0.2259])\n",
        "gtsrb_transforms = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb96Fte9fix8"
      },
      "outputs": [],
      "source": [
        "#dataset =  (root='./datasets' , download=True, train=True, transform = gtsrb_transforms)\n",
        "train_path = \"GTSRB/datasets/Train\"\n",
        "\n",
        "full_gtsrb_dataset = datasets.ImageFolder(root=train_path, transform=gtsrb_transforms)\n",
        "\n",
        "train_size = int(0.8 * len(full_gtsrb_dataset))\n",
        "test_size = len(full_gtsrb_dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(full_gtsrb_dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKUjj0shpYkD",
        "outputId": "5457bdd2-98b8-4226-8df5-277ab6fca797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 31367\n",
            "Testing samples: 7842\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Testing samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjOO-fBLuvE0"
      },
      "outputs": [],
      "source": [
        "# Initialize labels to numbers\n",
        "classes, class_names = class_formation()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "w4mxcVmCO8dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for x_batch, y_batch in train_dataloader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epochs%10==0:\n",
        "            predictions, labels = evaluate_model(model, test_dataloader, device)\n",
        "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "0FcMYcTfNITX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_model = resnet_18()\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.SGD(actual_model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = 5e-4)"
      ],
      "metadata": {
        "id": "9CWwp3F5UxN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Sparsity\n",
        "print(f\"RESNET 18 global sparsity = {compute_sparsity_resnet(actual_model):.2f}%\")"
      ],
      "metadata": {
        "id": "fJsKD90ajR2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change function based on prune method: l1unstructured_prune, global_prune_resnet, layered_structured_prune_resnet\n",
        "pruned_model = l1unstructured_prune(actual_model)"
      ],
      "metadata": {
        "id": "KbDhTgSMjsdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-Calculate Sparsity\n",
        "print(f\"RESNET 18 global sparsity = {compute_sparsity_resnet(actual_model):.2f}%\")"
      ],
      "metadata": {
        "id": "658lLJrckbxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual training of model\n",
        "prepruned_model = train_model(model = actual_model.to(device), epochs = epochs)"
      ],
      "metadata": {
        "id": "-DmzihVZVTI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepruned_model.to(device)\n",
        "prepruned_model.eval()\n",
        "\n",
        "predictions, labels = evaluate_model(prepruned_model, test_dataloader, device)\n",
        "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
        "print(f\"RESNET-18 Pre-Train Pruning Model test accuracy: {(100 * test_acc):.2f}%\")"
      ],
      "metadata": {
        "id": "6dWwdV_UXbLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model_path = Path(\"GTSRB/models\")\n",
        "model_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model_name = \"preprune_resnet_l1.pth\" # Change path based on pruning method\n",
        "model_save_path = model_path / model_name\n",
        "\n",
        "print(f\"Saving the model: {model_save_path}\")\n",
        "torch.save(obj=prepruned_model.state_dict(), f=model_save_path)"
      ],
      "metadata": {
        "id": "WFu1ARwcXesZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
