{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pip Installs"
      ],
      "metadata": {
        "id": "8Y8QGIhq-k3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!pip install cleverhans\n",
        "!pip install quantus\n",
        "!pip install captum\n",
        "!pip install ranger-adabelief"
      ],
      "metadata": {
        "id": "ETgLVNWO-oOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "EixHUPJz-srq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "import torch.optim as optim\n",
        "from cleverhans.torch.attacks.projected_gradient_descent import (projected_gradient_descent)\n",
        "\n",
        "import quantus\n",
        "import captum\n",
        "from captum.attr import Saliency, IntegratedGradients, NoiseTunnel\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import copy\n",
        "import gc\n",
        "import math\n",
        "\n",
        "import warnings\n",
        "\n",
        "import os\n",
        "from itertools import chain\n",
        "\n",
        "from collections import Counter\n",
        "from ranger_adabelief import RangerAdaBelief"
      ],
      "metadata": {
        "id": "0QChV1hu-t6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Formation"
      ],
      "metadata": {
        "id": "NkmuUNcVNT0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def class_formation():\n",
        "  classes = {\n",
        "    0: 'Speed limit (20km/h)',\n",
        "    1: 'Speed limit (30km/h)',\n",
        "    2: 'Speed limit (50km/h)',\n",
        "    3: 'Speed limit (60km/h)',\n",
        "    4: 'Speed limit (70km/h)',\n",
        "    5: 'Speed limit (80km/h)',\n",
        "    6: 'End of speed limit (80km/h)',\n",
        "    7: 'Speed limit (100km/h)',\n",
        "    8: 'Speed limit (120km/h)',\n",
        "    9: 'No passing',\n",
        "    10: 'No passing veh over 3.5 tons',\n",
        "    11: 'Right-of-way at intersection',\n",
        "    12: 'Priority road',\n",
        "    13: 'Yield',\n",
        "    14: 'Stop',\n",
        "    15: 'No vehicles',\n",
        "    16: 'Veh > 3.5 tons prohibited',\n",
        "    17: 'No entry',\n",
        "    18: 'General caution',\n",
        "    19: 'Dangerous curve left',\n",
        "    20: 'Dangerous curve right',\n",
        "    21: 'Double curve',\n",
        "    22: 'Bumpy road',\n",
        "    23: 'Slippery road',\n",
        "    24: 'Road narrows on the right',\n",
        "    25: 'Road work',\n",
        "    26: 'Traffic signals',\n",
        "    27: 'Pedestrians',\n",
        "    28: 'Children crossing',\n",
        "    29: 'Bicycles crossing',\n",
        "    30: 'Beware of ice/snow',\n",
        "    31: 'Wild animals crossing',\n",
        "    32: 'End speed + passing limits',\n",
        "    33: 'Turn right ahead',\n",
        "    34: 'Turn left ahead',\n",
        "    35: 'Ahead only',\n",
        "    36: 'Go straight or right',\n",
        "    37: 'Go straight or left',\n",
        "    38: 'Keep right',\n",
        "    39: 'Keep left',\n",
        "    40: 'Roundabout mandatory',\n",
        "    41: 'End of no passing',\n",
        "    42: 'End no passing veh > 3.5 tons',\n",
        "  }\n",
        "\n",
        "  class_names = list(classes.values())\n",
        "  return classes, class_names"
      ],
      "metadata": {
        "id": "0cKd5I1tNVQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Eval"
      ],
      "metadata": {
        "id": "G6C8il-OGW_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    This function evaluates the model using test dataset\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    prediction = torch.Tensor().to(device)\n",
        "    labels = torch.LongTensor().to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in dataloader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            prediction = torch.cat([prediction, model(x_batch)])\n",
        "            labels = torch.cat([labels, y_batch])\n",
        "\n",
        "    # passing the logits through Softmax layer to get predicted class\n",
        "    prediction = torch.nn.functional.softmax(prediction, dim=1)\n",
        "\n",
        "    return prediction, labels"
      ],
      "metadata": {
        "id": "ObE6VH5gGY_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparisty Functions"
      ],
      "metadata": {
        "id": "7ptcPkHj-Av4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW6nx8Wrdo7g"
      },
      "outputs": [],
      "source": [
        "def compute_sparsity_vgg(model):\n",
        "\n",
        "    conv1_sparsity = (torch.sum(model.features[0].weight == 0) / model.features[0].weight.nelement()) * 100\n",
        "    conv2_sparsity = (torch.sum(model.features[2].weight == 0) / model.features[2].weight.nelement()) * 100\n",
        "    conv3_sparsity = (torch.sum(model.features[5].weight == 0) / model.features[5].weight.nelement()) * 100\n",
        "    conv4_sparsity = (torch.sum(model.features[7].weight == 0) / model.features[7].weight.nelement()) * 100\n",
        "    conv5_sparsity = (torch.sum(model.features[10].weight == 0) / model.features[10].weight.nelement()) * 100\n",
        "    conv6_sparsity = (torch.sum(model.features[12].weight == 0) / model.features[12].weight.nelement()) * 100\n",
        "    conv7_sparsity = (torch.sum(model.features[14].weight == 0) / model.features[14].weight.nelement()) * 100\n",
        "    conv8_sparsity = (torch.sum(model.features[17].weight == 0) / model.features[17].weight.nelement()) * 100\n",
        "    conv9_sparsity = (torch.sum(model.features[19].weight == 0) / model.features[19].weight.nelement()) * 100\n",
        "    conv10_sparsity = (torch.sum(model.features[21].weight == 0) / model.features[21].weight.nelement()) * 100\n",
        "    conv11_sparsity = (torch.sum(model.features[24].weight == 0) / model.features[24].weight.nelement()) * 100\n",
        "    conv12_sparsity = (torch.sum(model.features[26].weight == 0) / model.features[26].weight.nelement()) * 100\n",
        "    conv13_sparsity = (torch.sum(model.features[28].weight == 0) / model.features[28].weight.nelement()) * 100\n",
        "    fc1_sparsity = (torch.sum(model.classifier[1].weight == 0) / model.classifier[1].weight.nelement()) * 100\n",
        "    fc2_sparsity = (torch.sum(model.classifier[4].weight == 0) / model.classifier[4].weight.nelement()) * 100\n",
        "    op_sparsity = (torch.sum(model.classifier[6].weight == 0) / model.classifier[6].weight.nelement()) * 100\n",
        "\n",
        "    num = torch.sum(model.features[0].weight == 0) + torch.sum(model.features[2].weight == 0) + torch.sum(model.features[5].weight == 0) + torch.sum(model.features[7].weight == 0) + torch.sum(model.features[10].weight == 0) + torch.sum(model.features[12].weight == 0) + torch.sum(model.features[14].weight == 0) + torch.sum(model.features[17].weight == 0) + torch.sum(model.features[19].weight == 0) + torch.sum(model.features[21].weight == 0)+ torch.sum(model.features[24].weight == 0) + torch.sum(model.features[26].weight == 0) + torch.sum(model.features[28].weight == 0) + torch.sum(model.classifier[1].weight == 0) + torch.sum(model.classifier[4].weight == 0) + torch.sum(model.classifier[6].weight == 0)\n",
        "    denom = model.features[0].weight.nelement() + model.features[2].weight.nelement() + model.features[5].weight.nelement() + model.features[7].weight.nelement() + model.features[10].weight.nelement() + model.features[12].weight.nelement() + model.features[14].weight.nelement() + model.features[17].weight.nelement() + model.features[19].weight.nelement() + model.features[21].weight.nelement() + model.features[24].weight.nelement() + model.features[26].weight.nelement() + model.features[28].weight.nelement() + model.classifier[1].weight.nelement() + model.classifier[4].weight.nelement() + model.classifier[6].weight.nelement()\n",
        "    global_sparsity = num/denom * 100\n",
        "    return global_sparsity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TVKf26V_805"
      },
      "outputs": [],
      "source": [
        "def compute_sparsity_resnet(model):\n",
        "\n",
        "    conv0_sparsity = (torch.sum(model.conv1.weight == 0) / model.conv1.weight.nelement()) * 100\n",
        "    bn0_sparsity = (torch.sum(model.bn1.weight == 0) / model.bn1.weight.nelement()) * 100\n",
        "\n",
        "    conv1_sparsity = (torch.sum(model.layer1[0].conv1.weight == 0) / model.layer1[0].conv1.weight.nelement()) * 100\n",
        "    bn1_sparsity = (torch.sum(model.layer1[0].bn1.weight == 0) / model.layer1[0].bn1.weight.nelement()) * 100\n",
        "\n",
        "    conv2_sparsity = (torch.sum(model.layer1[0].conv2.weight == 0) / model.layer1[0].conv2.weight.nelement()) * 100\n",
        "    bn2_sparsity = (torch.sum(model.layer1[0].bn2.weight == 0) / model.layer1[0].bn2.weight.nelement()) * 100\n",
        "\n",
        "    conv3_sparsity = (torch.sum(model.layer1[1].conv1.weight == 0) / model.layer1[1].conv1.weight.nelement()) * 100\n",
        "    bn3_sparsity = (torch.sum(model.layer1[1].bn1.weight == 0) / model.layer1[1].bn1.weight.nelement()) * 100\n",
        "\n",
        "    conv4_sparsity = (torch.sum(model.layer1[1].conv2.weight == 0) / model.layer1[1].conv2.weight.nelement()) * 100\n",
        "    bn4_sparsity = (torch.sum(model.layer1[1].bn2.weight == 0) / model.layer1[1].bn2.weight.nelement()) * 100\n",
        "\n",
        "    conv5_sparsity = (torch.sum(model.layer2[0].conv1.weight == 0) / model.layer2[0].conv1.weight.nelement()) * 100\n",
        "    bn5_sparsity = (torch.sum(model.layer2[0].bn1.weight == 0) / model.layer2[0].bn1.weight.nelement()) * 100\n",
        "\n",
        "    conv6_sparsity = (torch.sum(model.layer2[0].conv2.weight == 0) / model.layer2[0].conv2.weight.nelement()) * 100\n",
        "    bn6_sparsity = (torch.sum(model.layer2[0].bn2.weight == 0) / model.layer2[0].bn2.weight.nelement()) * 100\n",
        "\n",
        "    conv7_sparsity = (torch.sum(model.layer2[1].conv1.weight == 0) / model.layer2[1].conv1.weight.nelement()) * 100\n",
        "    bn7_sparsity = (torch.sum(model.layer2[1].bn1.weight == 0) / model.layer2[1].bn1.weight.nelement()) * 100\n",
        "\n",
        "    conv8_sparsity = (torch.sum(model.layer2[1].conv2.weight == 0) / model.layer2[1].conv2.weight.nelement()) * 100\n",
        "    bn8_sparsity = (torch.sum(model.layer2[1].bn2.weight == 0) / model.layer2[1].bn2.weight.nelement()) * 100\n",
        "\n",
        "    conv9_sparsity = (torch.sum(model.layer3[0].conv1.weight == 0) / model.layer3[0].conv1.weight.nelement()) * 100\n",
        "    bn9_sparsity = (torch.sum(model.layer3[0].bn1.weight == 0) / model.layer3[0].bn1.weight.nelement()) * 100\n",
        "\n",
        "    conv10_sparsity = (torch.sum(model.layer3[0].conv2.weight == 0) / model.layer3[0].conv2.weight.nelement()) * 100\n",
        "    bn10_sparsity = (torch.sum(model.layer3[0].bn2.weight == 0) / model.layer3[0].bn2.weight.nelement()) * 100\n",
        "\n",
        "    conv11_sparsity = (torch.sum(model.layer3[1].conv1.weight == 0) / model.layer3[1].conv1.weight.nelement()) * 100\n",
        "    bn11_sparsity = (torch.sum(model.layer3[1].bn1.weight == 0) / model.layer3[1].bn1.weight.nelement()) * 100\n",
        "\n",
        "    conv12_sparsity = (torch.sum(model.layer3[1].conv2.weight == 0) / model.layer3[1].conv2.weight.nelement()) * 100\n",
        "    bn12_sparsity = (torch.sum(model.layer3[1].bn2.weight == 0) / model.layer3[1].bn2.weight.nelement()) * 100\n",
        "\n",
        "    conv13_sparsity = (torch.sum(model.layer4[0].conv1.weight == 0) / model.layer4[0].conv1.weight.nelement()) * 100\n",
        "    bn13_sparsity = (torch.sum(model.layer4[0].bn1.weight == 0) / model.layer4[0].bn1.weight.nelement()) * 100\n",
        "\n",
        "    conv14_sparsity = (torch.sum(model.layer4[0].conv2.weight == 0) / model.layer4[0].conv2.weight.nelement()) * 100\n",
        "    bn14_sparsity = (torch.sum(model.layer4[0].bn2.weight == 0) / model.layer4[0].bn2.weight.nelement()) * 100\n",
        "\n",
        "    conv15_sparsity = (torch.sum(model.layer4[1].conv1.weight == 0) / model.layer4[1].conv1.weight.nelement()) * 100\n",
        "    bn15_sparsity = (torch.sum(model.layer4[1].bn1.weight == 0) / model.layer4[1].bn1.weight.nelement()) * 100\n",
        "\n",
        "    conv16_sparsity = (torch.sum(model.layer4[1].conv2.weight == 0) / model.layer4[1].conv2.weight.nelement()) * 100\n",
        "    bn16_sparsity = (torch.sum(model.layer4[1].bn2.weight == 0) / model.layer4[1].bn2.weight.nelement()) * 100\n",
        "\n",
        "    fc_sparsity = (torch.sum(model.fc.weight == 0) / model.fc.weight.nelement()) * 100\n",
        "\n",
        "    num =  torch.sum(model.conv1.weight == 0) + torch.sum(model.bn1.weight == 0) + torch.sum(model.layer1[0].conv1.weight == 0) + torch.sum(model.layer1[0].bn1.weight == 0) + torch.sum(model.layer1[0].conv2.weight == 0) +  torch.sum(model.layer1[0].bn2.weight == 0) + torch.sum(model.layer1[1].conv1.weight == 0) +  torch.sum(model.layer1[1].bn1.weight == 0) + torch.sum(model.layer1[1].conv2.weight == 0) + torch.sum(model.layer1[1].bn2.weight == 0) +torch.sum(model.layer2[0].conv1.weight == 0) + torch.sum(model.layer2[0].bn1.weight == 0) + torch.sum(model.layer2[0].conv2.weight == 0) +  torch.sum(model.layer2[0].bn2.weight == 0) + torch.sum(model.layer2[1].conv1.weight == 0) + torch.sum(model.layer2[1].bn1.weight == 0) + torch.sum(model.layer2[1].conv2.weight == 0) + torch.sum(model.layer2[1].bn2.weight == 0) + torch.sum(model.layer3[0].conv1.weight == 0) + torch.sum(model.layer3[0].bn1.weight == 0) + torch.sum(model.layer3[0].conv2.weight == 0) +  torch.sum(model.layer3[0].bn2.weight == 0) + torch.sum(model.layer3[1].conv1.weight == 0) +  torch.sum(model.layer3[1].bn1.weight == 0) + torch.sum(model.layer3[1].conv2.weight == 0) + torch.sum(model.layer3[1].bn2.weight == 0) + torch.sum(model.layer4[0].conv1.weight == 0) + torch.sum(model.layer4[0].bn1.weight == 0) + torch.sum(model.layer4[0].conv2.weight == 0) +  torch.sum(model.layer4[0].bn2.weight == 0) + torch.sum(model.layer4[1].conv1.weight == 0) +  torch.sum(model.layer4[1].bn1.weight == 0) + torch.sum(model.layer4[1].conv2.weight == 0) + torch.sum(model.layer4[1].bn2.weight == 0) + torch.sum(model.fc.weight == 0)\n",
        "\n",
        "    denom =  model.conv1.weight.nelement() +  model.bn1.weight.nelement() + model.layer1[0].conv1.weight.nelement() + model.layer1[0].bn1.weight.nelement() + model.layer1[0].conv2.weight.nelement() + model.layer1[0].bn2.weight.nelement() + model.layer1[1].conv1.weight.nelement() +  model.layer1[1].bn1.weight.nelement() + model.layer1[1].conv2.weight.nelement() + model.layer1[1].bn2.weight.nelement() +  model.layer2[0].conv1.weight.nelement() + model.layer2[0].bn1.weight.nelement() + model.layer2[0].conv2.weight.nelement() + model.layer2[0].bn2.weight.nelement() + model.layer2[1].conv1.weight.nelement() +  model.layer2[1].bn1.weight.nelement() + model.layer2[1].conv2.weight.nelement() + model.layer2[1].bn2.weight.nelement() +  model.layer3[0].conv1.weight.nelement() + model.layer3[0].bn1.weight.nelement() + model.layer3[0].conv2.weight.nelement() + model.layer3[0].bn2.weight.nelement() + model.layer3[1].conv1.weight.nelement() +  model.layer3[1].bn1.weight.nelement() + model.layer3[1].conv2.weight.nelement() + model.layer3[1].bn2.weight.nelement() +  model.layer4[0].conv1.weight.nelement() + model.layer4[0].bn1.weight.nelement() + model.layer4[0].conv2.weight.nelement() + model.layer4[0].bn2.weight.nelement() + model.layer4[1].conv1.weight.nelement() +  model.layer4[1].bn1.weight.nelement() + model.layer4[1].conv2.weight.nelement() + model.layer4[1].bn2.weight.nelement() + model.fc.weight.nelement()\n",
        "    global_sparsity = num/denom * 100\n",
        "    return global_sparsity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruning Functions"
      ],
      "metadata": {
        "id": "N7d_O4Yy-Zf2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfwXF37nWk0z"
      },
      "source": [
        "L1 Unstructured Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2-4H0MZXUda"
      },
      "outputs": [],
      "source": [
        "def l1unstructured_prune(input_model):\n",
        "  for name, module in input_model.named_modules():\n",
        "    # 20% of weights/connections pruned for all hidden layers\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.2)\n",
        "\n",
        "    # 10% of weights/connections pruned for output layer\n",
        "    elif isinstance(module, torch.nn.Linear):\n",
        "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.1)\n",
        "  return input_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMZLM49rXROB"
      },
      "source": [
        "Global Pruning - ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAON5xwAoaMT"
      },
      "outputs": [],
      "source": [
        "def global_prune_resnet(input_model)\n",
        "  parameters_to_prune = (\n",
        "    (input_model.conv1, 'weight'),\n",
        "    (input_model.bn1, 'weight'),\n",
        "    (input_model.layer1[0].conv1, 'weight'),\n",
        "    (input_model.layer1[0].bn1, 'weight'),\n",
        "    (input_model.layer1[0].conv2, 'weight'),\n",
        "    (input_model.layer1[0].bn2, 'weight'),\n",
        "    (input_model.layer1[1].conv1, 'weight'),\n",
        "    (input_model.layer1[1].bn1, 'weight'),\n",
        "    (input_model.layer1[1].conv2, 'weight'),\n",
        "    (input_model.layer1[1].bn2, 'weight'),\n",
        "    (input_model.layer2[0].conv1, 'weight'),\n",
        "    (input_model.layer2[0].bn1, 'weight'),\n",
        "    (input_model.layer2[0].conv2, 'weight'),\n",
        "    (input_model.layer2[0].bn2, 'weight'),\n",
        "    (input_model.layer2[1].conv1, 'weight'),\n",
        "    (input_model.layer2[1].bn1, 'weight'),\n",
        "    (input_model.layer2[1].conv2, 'weight'),\n",
        "    (input_model.layer2[1].bn2, 'weight'),\n",
        "    (input_model.layer3[0].conv1, 'weight'),\n",
        "    (input_model.layer3[0].bn1, 'weight'),\n",
        "    (input_model.layer3[0].conv2, 'weight'),\n",
        "    (input_model.layer3[0].bn2, 'weight'),\n",
        "    (input_model.layer3[1].conv1, 'weight'),\n",
        "    (input_model.layer3[1].bn1, 'weight'),\n",
        "    (input_model.layer3[1].conv2, 'weight'),\n",
        "    (input_model.layer3[1].bn2, 'weight'),\n",
        "    (input_model.layer4[0].conv1, 'weight'),\n",
        "    (input_model.layer4[0].bn1, 'weight'),\n",
        "    (input_model.layer4[0].conv2, 'weight'),\n",
        "    (input_model.layer4[0].bn2, 'weight'),\n",
        "    (input_model.layer4[1].conv1, 'weight'),\n",
        "    (input_model.layer4[1].bn1, 'weight'),\n",
        "    (input_model.layer4[1].conv2, 'weight'),\n",
        "    (input_model.layer4[1].bn2, 'weight'),\n",
        "    (input_model.fc, 'weight')\n",
        "    )\n",
        "\n",
        "  prune_rates_global = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "  for iter_prune_round in range(1):\n",
        "    print(f\"\\n\\nIterative Global pruning round = {iter_prune_round + 1}\")\n",
        "\n",
        "    # Prune layer-wise in a structured manner-\n",
        "    prune.global_unstructured(\n",
        "        parameters_to_prune,\n",
        "        pruning_method = prune.L1Unstructured,\n",
        "        amount = prune_rates_global[iter_prune_round]\n",
        "    )\n",
        "  return input_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdIjOmDvhAfS"
      },
      "source": [
        "Global Pruning - VGG"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameters to prune for the VGG16 model\n",
        "def global_prune_vgg(input_model):\n",
        "  parameters_to_prune = (\n",
        "      (input_model.features[0], 'weight'),\n",
        "      (input_model.features[2], 'weight'),\n",
        "      (input_model.features[5], 'weight'),\n",
        "      (input_model.features[7], 'weight'),\n",
        "      (input_model.features[10], 'weight'),\n",
        "      (input_model.features[12], 'weight'),\n",
        "      (input_model.features[14], 'weight'),\n",
        "      (input_model.features[17], 'weight'),\n",
        "      (input_model.features[19], 'weight'),\n",
        "      (input_model.features[21], 'weight'),\n",
        "      (input_model.features[24], 'weight'),\n",
        "      (input_model.features[26], 'weight'),\n",
        "      (input_model.features[28], 'weight'),\n",
        "      (input_model.classifier[1], 'weight'),\n",
        "      (input_model.classifier[4], 'weight'),\n",
        "      (input_model.classifier[6], 'weight')\n",
        "  )\n",
        "\n",
        "# Define pruning rates\n",
        "  prune_rates_global = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "  for iter_prune_round in range(1):\n",
        "    print(f\"\\n\\nIterative Global pruning round = {iter_prune_round + 1}\")\n",
        "\n",
        "    # Prune layer-wise in a structured manner\n",
        "    prune.global_unstructured(\n",
        "        parameters_to_prune,\n",
        "        pruning_method=prune.L1Unstructured,\n",
        "        amount=prune_rates_global[iter_prune_round]\n",
        "    )\n",
        "  return input_model"
      ],
      "metadata": {
        "id": "zom3vyeZ-4TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4jrbfJtXSYf"
      },
      "source": [
        "Layered Structured Pruning - ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "348h5UDSqoyg",
        "outputId": "bf94140a-0606-401a-d3f5-495023a509a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=512, out_features=43, bias=True)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prune layer-wise in a structured manner-\n",
        "def layeredstructured_prune_resnet(input_model):\n",
        "  prune.ln_structured(input_model.conv1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer1[0].conv1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer1[0].conv2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer1[1].conv1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer1[1].conv2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer2[0].conv1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer2[0].conv2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer2[1].conv1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer2[1].conv2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer3[0].conv1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer3[0].conv2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer3[1].conv1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer3[1].conv2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer4[0].conv1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer4[0].conv2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer4[1].conv1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "  prune.ln_structured(input_model.layer4[1].conv2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "\n",
        "  prune.ln_structured(input_model.fc, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
        "\n",
        "  return input_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShewiFhKZL2i"
      },
      "source": [
        "Layered Structured Pruning - VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nJ89xHOKXfi",
        "outputId": "fb9d316c-a224-4cf9-c86e-94b88e81617c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=512, out_features=43, bias=True)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def layeredstructured_prune_vgg(input_model):\n",
        "\n",
        "  prune.ln_structured(input_model.features[0], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.features[2], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "\n",
        "  prune.ln_structured(input_model.features[5], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.features[7], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "\n",
        "  prune.ln_structured(input_model.features[10], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.features[12], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.features[14], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "\n",
        "  prune.ln_structured(input_model.features[17], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.features[19], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.features[21], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "\n",
        "  prune.ln_structured(input_model.features[24], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.features[26], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.features[28], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "\n",
        "  prune.ln_structured(input_model.classifier[1], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.classifier[4], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "  prune.ln_structured(input_model.classifier[6], name=\"weight\", amount=0.1, n=2, dim=0)\n",
        "\n",
        "  return input_model"
      ]
    }
  ]
}
