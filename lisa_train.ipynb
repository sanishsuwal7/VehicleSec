{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5aba7-5a19-40bc-8cb6-7b35e135d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import quantus\n",
    "import captum\n",
    "from captum.attr import Saliency, IntegratedGradients, NoiseTunnel\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (projected_gradient_descent)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import gc\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from lisa import LISA\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from ranger import Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b3690-cab6-47dc-9bd1-911ed82c22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SubsetLISA(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset for the LISA subset, created using filtered image and label tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_tensor_path, label_tensor_path,train:bool, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_tensor_path (str): Path to the images tensor file.\n",
    "            label_tensor_path (str): Path to the labels tensor file.\n",
    "            transform (callable, optional): A function/transform to apply to the images.\n",
    "        \"\"\"\n",
    "        self.images = torch.load(image_tensor_path)\n",
    "        self.labels = torch.load(label_tensor_path)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self._train_test_split()\n",
    "\n",
    "        assert len(self.images) == len(self.labels), \"Images and labels length mismatch\"\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index of the sample.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, label) where image is the input tensor and label is the target tensor.\n",
    "        \"\"\"\n",
    "        image = self.images[index]\n",
    "        target = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def _train_test_split(self, test_percent: float = 0.16):\n",
    "        classes = {}\n",
    "        for i, cl in enumerate(self.labels.numpy()):\n",
    "            arr = classes.get(cl, [])\n",
    "            arr.append(i)\n",
    "            classes[cl] = arr\n",
    "\n",
    "        train, test = [], []\n",
    "        for cl, arr in classes.items():\n",
    "            split_index = int(len(arr) * test_percent)\n",
    "            test = test + arr[:split_index]\n",
    "            train = train + arr[split_index:]\n",
    "\n",
    "        sub = train if self.train else test\n",
    "        self.images, self.labels = self.images[sub], self.labels[sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa97af-bc4d-4439-8087-2186053ff344",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.ipynb\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfc8e0-7dd8-488b-a94d-5ee6c400b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.4563, 0.4076, 0.3895], std=[0.2298, 0.2144, 0.2259])\n",
    "\n",
    "lisa_transforms = transforms.Compose([ transforms.ToPILImage(),transforms.ToTensor(),normalize])\n",
    "\n",
    "# Paths to the saved subset tensors\n",
    "image_tensor_path = \"datasets/lisa-batches/subset_images.tensor\"  # Replace with your actual file path\n",
    "label_tensor_path = \"datasets/lisa-batches/subset_labels2.tensor\"  # Replace with your actual file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136affa-438a-4bd8-9398-65c3860f9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "train_dataset = SubsetLISA(image_tensor_path, label_tensor_path, train=True, transform = lisa_transforms)\n",
    "test_dataset = SubsetLISA(image_tensor_path, label_tensor_path, train=False, transform = lisa_transforms)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,) # num_workers=4,\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc3de4-91d8-48c1-b734-72877aa62a9e",
   "metadata": {},
   "source": [
    "# Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330b298-22fd-4a93-8300-6eb4a6d437b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16()\n",
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf704b-3ada-4c5d-907b-5de7569d3091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model!\n",
    "        if epochs%10==0:\n",
    "            predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5e8bc-a925-4367-8bd3-5c65fe7c4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normal = train_model(model=model.to(device),epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee19afb-ff30-4d8c-abbd-0582fe22c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_normal, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG LISA Normal is: {(100 * test_acc):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25e36e-b488-46ec-9df6-0955df225694",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_normal.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model_normal.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f15a2-ecf0-476b-a9b6-2111235ca5f9",
   "metadata": {},
   "source": [
    "# Adversarial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa191e9-127e-45e9-8120-71e4ef9a8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16()\n",
    "learning_rate = 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = 5e-4)\n",
    "eps= [0.01, 0.03, 0.06, 0.1, 0.3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84b99a-1b85-4b5a-8018-9dc067c31aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adv(model, epsilon, epochs):\n",
    "    model.train()\n",
    "    eps = epsilon\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            x_batch = projected_gradient_descent(model, x_batch, eps, eps/10, 40, np.inf)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model!\n",
    "        if epochs%10==0:\n",
    "            predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3860b8c-5063-42e3-8a1f-3b700cc1aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adversarial = train_adv(model=model.to(device),epsilon = eps[3], epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba5557-52ac-49a6-aef0-29b03877827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to GPU and eval mode.\n",
    "model_adversarial.to(device)\n",
    "model_adversarial.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca195f-1106-4e9e-94d5-cbefde883266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_adversarial, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Adversarial Model test accuracy: {(100 * test_acc):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27474479-eb86-45f5-86b2-26365b46ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_adv.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model_adversarial.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f8661-6499-4b4d-9324-8d768f8f03d0",
   "metadata": {},
   "source": [
    "# L1 Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfd079-b618-4b39-96e2-a698b137b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16()\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 5e-4)\n",
    "print(f\"VGG-16 global sparsity = {compute_sparsity_vgg(model):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38976ccb-3058-493e-8f8b-1613863dc470",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"VGG-16 global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    # prune 20% of weights/connections in for all hidden layaers-\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.2)\n",
    "    \n",
    "    # prune 10% of weights/connections for output layer-\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.1)\n",
    "\n",
    "print(f\"VGG-16 global sparsity = {compute_sparsity_vgg(model):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067296a-6ec2-4f69-892f-0d9bce092366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l1_unstructured = train_model(model = model.to(device), epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d845e-c7b0-4ed5-acad-816a908d0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_l1_pre.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model_l1_unstructured.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bea71b-b0c5-4fa9-89e2-d4a35e6c4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_l1_unstructured, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG LISA L1 pre is: {(100 * test_acc):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02038e6-f746-4e40-a1ef-1f19909e5add",
   "metadata": {},
   "source": [
    "# L1 Post No Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed39de0-d4b4-4884-bd41-4fb6348de1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_normal.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "model = vgg16().to(device)\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "print(f\"VGG-16 global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    # prune 20% of weights/connections in for all hidden layaers-\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.2)\n",
    "    \n",
    "    # prune 10% of weights/connections for output layer-\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.1)\n",
    "\n",
    "print(f\"VGG-16 global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG-16 pretrained no tuning is: {(100 * test_acc):.2f}%\")\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_l1_post_notune.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f72dc00-c62f-42f5-99d9-bbdef3d1154e",
   "metadata": {},
   "source": [
    "# L1 Post Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7260bc-fddb-429c-91c3-dfa979396f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 5e-4)\n",
    "\n",
    "def train_model(model, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model!\n",
    "        if epochs%10==0:\n",
    "            predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model\n",
    "\n",
    "model_tuned = train_model(model = model.to(device), epochs = epochs)\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_tuned, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG LISA L1 tuned post  is: {(100 * test_acc):.2f}%\")\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_l1_post_tuned.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model_tuned.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4f090-d263-441b-b24f-e62b32fb8051",
   "metadata": {},
   "source": [
    "# Global Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06463dc3-3a26-46b3-8794-ed64b3330625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16()\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 5e-4)\n",
    "\n",
    "print(f\"VGG-16 global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (model.features[0], 'weight'),\n",
    "    (model.features[2], 'weight'),\n",
    "    (model.features[5], 'weight'),\n",
    "    (model.features[7], 'weight'),\n",
    "    (model.features[10], 'weight'),\n",
    "    (model.features[12], 'weight'),\n",
    "    (model.features[14], 'weight'),\n",
    "    (model.features[17], 'weight'),\n",
    "    (model.features[19], 'weight'),\n",
    "    (model.features[21], 'weight'),\n",
    "    (model.features[24], 'weight'),\n",
    "    (model.features[26], 'weight'),\n",
    "    (model.features[28], 'weight'),\n",
    "    (model.classifier[1], 'weight'),\n",
    "    (model.classifier[4], 'weight'),\n",
    "    (model.classifier[6], 'weight')\n",
    ")\n",
    "\n",
    "prune_rates_global = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "def train_global_pruned(model, epochs):\n",
    "    for iter_prune_round in range(1):\n",
    "        print(f\"\\n\\nIterative Global pruning round = {iter_prune_round + 1}\")\n",
    "        \n",
    "        # Prune layer-wise in a structured manner-\n",
    "        prune.global_unstructured(\n",
    "            parameters_to_prune,\n",
    "            pruning_method = prune.L1Unstructured,\n",
    "            amount = prune_rates_global[iter_prune_round]\n",
    "            \n",
    "        )\n",
    "    \n",
    "        # Print current global sparsity level-\n",
    "        print(f\"VGG global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "        \n",
    "        \n",
    "        # Fine-training loop-\n",
    "        print(\"\\nFine-tuning pruned model to recover model's performance\\n\")\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for x_batch, y_batch in train_dataloader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(x_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "            # Evaluate model!\n",
    "            if epochs%10==0:\n",
    "                predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "                test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model\n",
    "\n",
    "model_global = train_global_pruned(model = model.to(device), epochs = epochs)\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_global, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG LISA Global pre is: {(100 * test_acc):.2f}%\")\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_global_pre.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model_global.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1b616-0875-47f0-8a15-723989f96751",
   "metadata": {},
   "source": [
    "# Global Post No Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26f63f-4594-42c0-a0ec-0358211ec8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_normal.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "model = vgg16().to(device)\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "print(f\"VGG-16 global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (model.features[0], 'weight'),\n",
    "    (model.features[2], 'weight'),\n",
    "    (model.features[5], 'weight'),\n",
    "    (model.features[7], 'weight'),\n",
    "    (model.features[10], 'weight'),\n",
    "    (model.features[12], 'weight'),\n",
    "    (model.features[14], 'weight'),\n",
    "    (model.features[17], 'weight'),\n",
    "    (model.features[19], 'weight'),\n",
    "    (model.features[21], 'weight'),\n",
    "    (model.features[24], 'weight'),\n",
    "    (model.features[26], 'weight'),\n",
    "    (model.features[28], 'weight'),\n",
    "    (model.classifier[1], 'weight'),\n",
    "    (model.classifier[4], 'weight'),\n",
    "    (model.classifier[6], 'weight')\n",
    ")\n",
    "\n",
    "prune_rates_global = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "for iter_prune_round in range(1):\n",
    "    print(f\"\\n\\nIterative Global pruning round = {iter_prune_round + 1}\")\n",
    "    \n",
    "    # Prune layer-wise in a structured manner-\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method = prune.L1Unstructured,\n",
    "        amount = prune_rates_global[iter_prune_round]\n",
    "    )\n",
    "\n",
    "    # Print current global sparsity level-\n",
    "    print(f\"VGG-16 global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG-16 pretrained no tuning is: {(100 * test_acc):.2f}%\")\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_global_post_notune.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e403926-0772-4798-a725-3793b2d01c3d",
   "metadata": {},
   "source": [
    "# Global Post Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858188e-579c-4705-9cb8-28a6f4d39e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 5e-4)\n",
    "\n",
    "def train_model(model, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model!\n",
    "        if epochs%10==0:\n",
    "            predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model\n",
    "\n",
    "model_tuned = train_model(model = model.to(device), epochs = epochs)\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_tuned, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG LISA Global post tuned is: {(100 * test_acc):.2f}%\")\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_global_post_tuned.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model_tuned.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742de81d-95fa-48b5-81da-c808140f70da",
   "metadata": {},
   "source": [
    "# Layered Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5673c0e-78af-46e0-8f0a-bab23758b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16().to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 5e-4)\n",
    "\n",
    "def train_layered_pruned(model, epochs):\n",
    "    for iter_prune_round in range(1):\n",
    "        print(f\"\\n\\nIterative Global pruning round = {iter_prune_round + 1}\")\n",
    "        \n",
    "        # Prune layer-wise in a structured manner-\n",
    "        prune.ln_structured(model.features[0], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[2], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[5], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[7], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[10], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[12], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[14], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[17], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[19], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[21], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[24], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[26], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[28], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.classifier[1], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.classifier[4], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.classifier[6], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        \n",
    "        # Print current global sparsity level-\n",
    "        print(f\"VGG global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "        \n",
    "        \n",
    "        # Fine-training loop-\n",
    "        print(\"\\nFine-tuning pruned model to recover model's performance\\n\")\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for x_batch, y_batch in train_dataloader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(x_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "            # Evaluate model!\n",
    "            if epochs%10==0:\n",
    "                predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "                test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model\n",
    "\n",
    "model_layered_structured = train_layered_pruned(model = model.to(device), epochs = epochs)\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_layered_structured, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG LISA Layered pre is: {(100 * test_acc):.2f}%\")\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_layered_pre.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model_layered_structured.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4dd3d-507f-4975-86f3-b919fa75388b",
   "metadata": {},
   "source": [
    "# Layered Post No Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d780b-0df3-47ba-9c06-1bd7b0bc38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_normal.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "model = vgg16().to(device)\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "print(f\"VGG-16 global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "\n",
    "for iter_prune_round in range(1):\n",
    "        print(f\"\\n\\nIterative Global pruning round = {iter_prune_round + 1}\")\n",
    "        \n",
    "        # Prune layer-wise in a structured manner-\n",
    "        prune.ln_structured(model.features[0], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[2], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[5], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[7], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[10], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[12], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[14], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[17], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[19], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[21], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[24], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[26], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.features[28], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.classifier[1], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.classifier[4], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.classifier[6], name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        \n",
    "        # Print current global sparsity level-\n",
    "        print(f\"VGG global sparsity = {compute_sparsity_vgg(model):.2f}%\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG-16 post no tuning is: {(100 * test_acc):.2f}%\")\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_layered_post_notune.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9745375-488d-4e01-b9dc-3c58cc0b6ac8",
   "metadata": {},
   "source": [
    "# Layered Post Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3775f-39a3-4d31-accd-e875bd62e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 5e-4)\n",
    "\n",
    "def train_model(model, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model!\n",
    "        if epochs%10==0:\n",
    "            predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model\n",
    "\n",
    "model_tuned = train_model(model = model.to(device), epochs = epochs)\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_tuned, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Test accuracy for VGG LISA Layered post tuned is: {(100 * test_acc):.2f}%\")\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"lisa_layered_post_tuned.pth\"\n",
    "model_save_path = model_path / model_name\n",
    "\n",
    "print(f\"Saving the model: {model_save_path}\")\n",
    "torch.save(obj=model_tuned.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d6001-cc23-4ff0-9164-2af5298d51b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae700e-b996-4ddb-a3ee-5de1e95d92b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
