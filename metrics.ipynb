{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb212874-417e-41f6-8054-ae675dff8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5775c3f-06b7-47f8-a5ff-5813146a3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_compute_road(model, test_loader, method, device,  resnet=False):\n",
    "    \"\"\"\n",
    "    This function calculates the ROAD metric for vanilla gradient and integrated gradient method\n",
    "\n",
    "    Args:\n",
    "        model: Model to calculate metric on\n",
    "        test_loader: test data loader\n",
    "        method: Vanilla Gradient or Integrated Gradients\n",
    "        device: use GPU or CPU\n",
    "        resnet: is it resnet model or not\n",
    "    \"\"\"\n",
    "    # if it is renet remove 10% of the features at once.\n",
    "    if resnet:\n",
    "        faithfulness = quantus.ROAD(\n",
    "        noise=0.01,\n",
    "        perturb_func=quantus.perturb_func.noisy_linear_imputation,\n",
    "        percentages=list(range(1, 100, 10)),\n",
    "        display_progressbar=False)\n",
    "    else: # if it is not renet remove 5% of the features at once.\n",
    "        faithfulness = quantus.ROAD(\n",
    "        noise=0.01,\n",
    "        perturb_func=quantus.perturb_func.noisy_linear_imputation,\n",
    "        percentages=list(range(1, 100, 5)),\n",
    "        display_progressbar=False)\n",
    "\n",
    "    score_list = []\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        # passing image through model\n",
    "        outputs = model(x_batch)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        # using only correct prediction\n",
    "        correct_mask = predictions == y_batch\n",
    "        x_batch = x_batch[correct_mask]\n",
    "        y_batch = y_batch[correct_mask]\n",
    "        x_batch, y_batch = x_batch.cpu().numpy(), y_batch.cpu().numpy()\n",
    "        # if the metric is SmoothGrad use custom explainer\n",
    "        if method == \"SmoothGrad\":\n",
    "             scores = faithfulness(\n",
    "                model= model,\n",
    "                x_batch=x_batch,\n",
    "                y_batch=y_batch,\n",
    "                a_batch=None,\n",
    "                s_batch=None,\n",
    "                device=device,\n",
    "                explain_func= explainer_wrapper,\n",
    "                explain_func_kwargs = {\n",
    "                    \"method\": method,\n",
    "                    \"posterior_mean\": copy.deepcopy(\n",
    "                        model\n",
    "                        .to(device)\n",
    "                        .state_dict()\n",
    "                    ),\n",
    "                    \"mean\": 1.0,\n",
    "                    \"std\": 0.5,\n",
    "                    \"n\": 25,\n",
    "                    \"device\": device,\n",
    "                },\n",
    "        )\n",
    "        else: # use in built explainer\n",
    "            scores = faithfulness(\n",
    "                    model= model,\n",
    "                    x_batch=x_batch,\n",
    "                    y_batch=y_batch,\n",
    "                    a_batch=None,\n",
    "                    s_batch=None,\n",
    "                    device=device,\n",
    "                    explain_func= quantus.explain,\n",
    "                    explain_func_kwargs = {\"method\": method, \"softmax\": False})\n",
    "        # appending scores in score list\n",
    "        score_list.append(scores)\n",
    "        # collecting 1000 score samples\n",
    "        if resnet:\n",
    "           if len(score_list) > 500:\n",
    "            break\n",
    "        else:\n",
    "             if len(score_list) > 1000:\n",
    "                break\n",
    "                 \n",
    "    average = {}\n",
    "    for d in score_list:\n",
    "        for key, value in d.items():\n",
    "            if key in average:\n",
    "                average[key] += value\n",
    "            else:\n",
    "                average[key] = value\n",
    "\n",
    "    # Divide the sum by the number of dictionaries to get the average\n",
    "    num_dicts = len(score_list)\n",
    "    for key in average.keys():\n",
    "        average[key] /= num_dicts\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2af45e60-ab9c-45d0-9fd2-9be42fd0a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_compute_input_stability(model, test_loader,method, device,  resnet=False):\n",
    "    \"\"\"\n",
    "    This function calculates the Input Stability metric for vanilla gradient and integrated gradient method\n",
    "    \n",
    "    Args:\n",
    "        model: Model to calculate metric on\n",
    "        test_loader: test data loader\n",
    "        method: Vanilla Gradient or Integrated Gradients\n",
    "        device: use GPU or CPU\n",
    "        resnet: is it resnet model or not\n",
    "    \"\"\"\n",
    "    # parameter for input stability metric\n",
    "    metrics = quantus.RelativeInputStability(\n",
    "        nr_samples =5,\n",
    "        return_aggregate=False,\n",
    "         disable_warnings=True,\n",
    "    )\n",
    "    score_list = []\n",
    "    for i, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        # using correct prediction only\n",
    "        correct_mask = predictions == y_batch\n",
    "        x_batch = x_batch[correct_mask]\n",
    "        y_batch = y_batch[correct_mask]\n",
    "        x_batch, y_batch = x_batch.cpu().numpy(), y_batch.cpu().numpy()\n",
    "        # if the metric is SmoothGrad use custom explainer\n",
    "        if method == \"SmoothGrad\":\n",
    "            scores = metrics(\n",
    "                model= model,\n",
    "                x_batch=x_batch,\n",
    "                y_batch=y_batch,\n",
    "                a_batch=None,\n",
    "                s_batch=None,\n",
    "                device=device,\n",
    "                explain_func= explainer_wrapper,\n",
    "                explain_func_kwargs = {\n",
    "                    \"method\": method,\n",
    "                    \"posterior_mean\": copy.deepcopy(\n",
    "                        model\n",
    "                        .to(device)\n",
    "                        .state_dict()\n",
    "                    ),\n",
    "                    \"mean\": 1.0,\n",
    "                    \"std\": 0.5,\n",
    "                    \"n\": 25,\n",
    "                    \"device\": device,\n",
    "                })\n",
    "        else:  # use in built explainer\n",
    "            scores = metrics(\n",
    "                    model= model,\n",
    "                    x_batch=x_batch,\n",
    "                    y_batch=y_batch,\n",
    "                    a_batch=None,\n",
    "                    s_batch=None,\n",
    "                    device=device,\n",
    "                    explain_func= quantus.explain, \n",
    "                    explain_func_kwargs = {\"method\": method, \"softmax\": False})\n",
    "        score_list.append(np.nanmean(scores))\n",
    "        # using 500 samples if resnet else 1000\n",
    "        if resnet:\n",
    "            if len(score_list) > 500:\n",
    "                break \n",
    "        else:\n",
    "            if len(score_list) > 1000:\n",
    "                break \n",
    "    return math.log(np.nanmean(score_list), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12895806-2113-4aa2-9a5c-fa0ea765eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_compute_output_stability(model, test_loader,method,  device,  resnet=False):\n",
    "    \"\"\"\n",
    "    This function calculates the Output Stability metric for Vanilla Gradient or Integrated Gradients method\n",
    "    \n",
    "    Args:\n",
    "        model: Model to calculate metric on\n",
    "        test_loader: test data loader\n",
    "        method: Vanilla Gradient or Integrated Gradients\n",
    "        device: use GPU or CPU\n",
    "        resnet: is it resnet model or not\n",
    "    \"\"\"\n",
    "    # metric for Output Stability\n",
    "    metrics = quantus.RelativeOutputStability(\n",
    "        nr_samples = 5,\n",
    "         return_aggregate=False,\n",
    "        disable_warnings=True,\n",
    "    )\n",
    "    score_list = []\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        # using correct prediction only\n",
    "        correct_mask = predictions == y_batch\n",
    "        x_batch = x_batch[correct_mask]\n",
    "        y_batch = y_batch[correct_mask]\n",
    "        x_batch, y_batch = x_batch.cpu().numpy(), y_batch.cpu().numpy()\n",
    "        # if the metric is SmoothGrad use custom explainer\n",
    "        if method == \"SmoothGrad\":\n",
    "             scores = metrics(\n",
    "                model= model,\n",
    "                x_batch=x_batch,\n",
    "                y_batch=y_batch,\n",
    "                a_batch=None,\n",
    "                s_batch=None,\n",
    "                device=device,\n",
    "                explain_func= explainer_wrapper,\n",
    "                explain_func_kwargs = {\n",
    "                    \"method\": method,\n",
    "                    \"posterior_mean\": copy.deepcopy(\n",
    "                        model\n",
    "                        .to(device)\n",
    "                        .state_dict()\n",
    "                    ),\n",
    "                    \"mean\": 1.0,\n",
    "                    \"std\": 0.5,\n",
    "                    \"n\": 25,\n",
    "                    \"device\": device,\n",
    "                })\n",
    "        else:# use in built explainer\n",
    "            scores = metrics(\n",
    "                    model= model,\n",
    "                    x_batch=x_batch,\n",
    "                    y_batch=y_batch,\n",
    "                    a_batch=None,\n",
    "                    s_batch=None,\n",
    "                    device=device,\n",
    "                    explain_func= quantus.explain, \n",
    "                    explain_func_kwargs = {\"method\": method, \"softmax\": False})\n",
    "        score_list.append(np.nanmean(scores))\n",
    "        # using 500 samples if resnet else 1000\n",
    "        if resnet:\n",
    "            if len(score_list) > 500:\n",
    "                break \n",
    "        else:\n",
    "            if len(score_list) > 1000:\n",
    "                break \n",
    "    return math.log(np.nanmean(score_list), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3f80589-3b04-4373-affc-84951b25fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_compute_sparsity(model, test_loader,method,  device, resnet=False):\n",
    "    \"\"\"\n",
    "    This function calculates the Sparsity metric for Vanilla Gradient or Integrated Gradients method\n",
    "    \n",
    "   Args:\n",
    "        model: Model to calculate metric on\n",
    "        test_loader: test data loader\n",
    "        method: Vanilla Gradient or Integrated Gradients\n",
    "        device: use GPU or CPU\n",
    "        resnet: is it resnet model or not\n",
    "    \"\"\"\n",
    "    sparsity = quantus.Sparseness(disable_warnings=True, return_aggregate=True)\n",
    "    score_sparsity = []\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        # using correct predictions\n",
    "        correct_mask = predictions == y_batch\n",
    "        x_batch = x_batch[correct_mask]\n",
    "        y_batch = y_batch[correct_mask]\n",
    "        x_batch, y_batch = x_batch.cpu().numpy(), y_batch.cpu().numpy()\n",
    "        # if the metric is SmoothGrad use custom explainer\n",
    "        if method == \"SmoothGrad\":\n",
    "             scores = sparsity(\n",
    "                model= model,\n",
    "                x_batch=x_batch,\n",
    "                y_batch=y_batch,\n",
    "                a_batch=None,\n",
    "                s_batch=None,\n",
    "                device=device,\n",
    "                 explain_func= explainer_wrapper,\n",
    "                explain_func_kwargs = {\n",
    "                    \"method\": method,\n",
    "                    \"posterior_mean\": copy.deepcopy(\n",
    "                        model\n",
    "                        .to(device)\n",
    "                        .state_dict()\n",
    "                    ),\n",
    "                    \"mean\": 1.0,\n",
    "                    \"std\": 0.5,\n",
    "                    \"n\": 25,\n",
    "                    \"device\": device,\n",
    "                })\n",
    "        else: # use in built explainer\n",
    "            scores = sparsity(\n",
    "                    model= model,\n",
    "                    x_batch=x_batch,\n",
    "                    y_batch=y_batch,\n",
    "                    a_batch=None,\n",
    "                    s_batch=None,\n",
    "                    device=device,\n",
    "                    explain_func= quantus.explain, \n",
    "                    explain_func_kwargs = {\"method\": method, \"softmax\": False})\n",
    "        score_sparsity.extend(scores)\n",
    "        # using 500 samples if resnet else 1000\n",
    "        if resnet:\n",
    "            if len(score_sparsity) > 500:\n",
    "                break\n",
    "        else:\n",
    "            if len(score_sparsity) > 1000:\n",
    "                break\n",
    "    return np.nanmean(score_sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be1683-7346-468b-95ef-da3a782df865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
