{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874546b2-70db-41ad-9194-e7f013ac6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import kornia\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f3be1b-72dc-44f9-8211-a26c84dd8d1f",
   "metadata": {},
   "source": [
    "# LENET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff225eff-5676-4796-bd5e-6f86a008d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for natural and adversarial LeNet Model \n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the LeNet model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Input: 1 channel, Output: 6 feature maps, Kernel size: 5x5\n",
    "        self.conv_1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        # Max pooling operation with a 2x2 window\n",
    "        self.pool_1 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        \n",
    "        # Input: 6 feature maps, Output: 16 feature maps, Kernel size: 5x5\n",
    "        self.conv_2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc_1 = torch.nn.Linear(256, 120)\n",
    "        self.relu_3 = torch.nn.ReLU()\n",
    "        self.fc_2 = torch.nn.Linear(120, 84)\n",
    "        self.relu_4 = torch.nn.ReLU()\n",
    "        self.fc_3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the model\n",
    "\n",
    "        Args:\n",
    "            inputs\n",
    "        \"\"\"\n",
    "        inputs = self.pool_1(self.relu_1(self.conv_1(inputs)))\n",
    "        inputs = self.pool_2(self.relu_2(self.conv_2(inputs)))\n",
    "        # Flatten the output from the convolutional layers into a 1D tensor\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "        inputs = self.relu_3(self.fc_1(inputs))\n",
    "        inputs = self.relu_4(self.fc_2(inputs))\n",
    "        # Pass through the output layer to obtain class scores\n",
    "        output = self.fc_3(inputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7cb4c5-d87d-42bf-a626-211331669dde",
   "metadata": {},
   "source": [
    "# VGG-16 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f0a2419-013f-4f4b-aea4-74a0a11c11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        \"\"\"\n",
    "        Initialize the VGG model.\n",
    "\n",
    "        Args:\n",
    "            features: A sequential module representing the convolutional layers.\n",
    "        \"\"\"\n",
    "        super(VGG,self).__init__()\n",
    "        self.features = features\n",
    "        \n",
    "        # Weight initialization for convolutional layers\n",
    "        # Iterate through all modules in the model\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                n = layer.kernel_size[0] * layer.kernel_size[1] * layer.out_channels\n",
    "                layer.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                # Bias initialization to zero\n",
    "                layer.bias.data.zero_()\n",
    "\n",
    "        # Fully connected layers for final classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(), # Dropout for regularization\n",
    "            nn.Linear(512,512), # Fully connected layer\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "    # Function to create layers based on configuration\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass through the VGG model.\n",
    "\n",
    "        Args:\n",
    "            x : Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        inputs = self.features(inputs)\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        output = self.classifier(inputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d220aca2-9a48-4eeb-8578-6905b486bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(configuration):\n",
    "    \"\"\"\n",
    "    Function to create layers for VGG-16 based on configuration\n",
    "    :param configuration: configuration\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    in_channels =3\n",
    "\n",
    "    # Iterate through the configuration to build layers\n",
    "    for layer_config  in configuration:\n",
    "        # 'M' represents a Max Pooling layer\n",
    "        if layer_config  == 'Max':\n",
    "            layers += [nn.MaxPool2d(kernel_size = 2, stride =2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, layer_config , kernel_size = 3, padding =1) # Convolutional layer\n",
    "            layers.append(conv2d)\n",
    "            layers.append(nn.ReLU(inplace = True))\n",
    "            # Update the input channels for the next layer\n",
    "            in_channels = layer_config \n",
    "     # Return the sequential model of layers\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Two Conv layers (number of filters , number of filters) + Max Pool\n",
    "configuration = [\n",
    "    64, 64, 'Max',\n",
    "    128, 128, 'Max',\n",
    "    256, 256, 256, 'Max',\n",
    "    512, 512, 512, 'Max',\n",
    "    512, 512, 512, 'Max']\n",
    "\n",
    "def vgg16():\n",
    "    \"\"\"\n",
    "    Function to create a VGG-16 model\n",
    "    \"\"\"\n",
    "    return VGG(make_layers(configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d227a0e-5899-49b4-b842-02fb13f280a5",
   "metadata": {},
   "source": [
    "# RESNET-18 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a7cb09b-05b3-41be-8547-c9cd86756eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"\n",
    "    3x3 convolution with padding.\n",
    "\n",
    "    Args:\n",
    "        in_planes : Number of input channels.\n",
    "        out_planes : Number of output channels (filters).\n",
    "        stride: Stride of the convolution. Default is 1.\n",
    "    \n",
    "    Returns:\n",
    "        nn.Conv2d: A 2D convolutional layer with 3x3 kernel size.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52145903-b4bb-407b-8df2-7e0acfefbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes, out_planes, stride =1):\n",
    "    \"\"\"\n",
    "    1x1 convolution.\n",
    "\n",
    "    Args:\n",
    "        in_planes: Number of input channels.\n",
    "        out_planes: Number of output channels (filters).\n",
    "        stride: Stride of the convolution. Default is 1.\n",
    "    \n",
    "    Returns:\n",
    "        nn.Conv2d: A 2D convolutional layer with 1x1 kernel size.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride = stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "34c28255-802d-47ba-8619-780d75094d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1 # Expansion factor for output channels used in ResNet blocks\n",
    "    num_layers = 2  # Number of layers in the block \n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        \"\"\"\n",
    "        Initialize a BasicBlock instance.\n",
    "    \n",
    "        Args:\n",
    "            inplanes : Number of input channels.\n",
    "            planes : Number of output channels for the convolutions.\n",
    "            stride: Stride for the first convolution. Default is 1.\n",
    "            downsample : Downsampling layer to match dimensions of the input and output for the residual connection.\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # only conv with possibly not 1 stride\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        # Batch Normalization\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # ReLU activation \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # if stride is not 1 then self.downsample cannot be None\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the BasicBlock.\n",
    "\n",
    "        Args:\n",
    "            x : Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after applying the block.\n",
    "        \"\"\"\n",
    "        identity = x\n",
    "         # First convolution, batch normalization, and ReLU activation\n",
    "        output = self.conv1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu(output)\n",
    "         # Second convolution and batch normalization\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "\n",
    "        # Apply downsampling to the identity if needed\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # the residual connection\n",
    "        \n",
    "        output += identity\n",
    "        output = self.relu(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def block_conv_info(self):\n",
    "        \"\"\"\n",
    "        Retrieve information about the convolutional layers in the block.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: information about the convolutional layers\n",
    "        \"\"\"\n",
    "        block_kernel_sizes = [3, 3]\n",
    "        block_strides = [self.stride, 1]\n",
    "        block_paddings = [1, 1]\n",
    "\n",
    "        return block_kernel_sizes, block_strides, block_paddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de963075-788c-4eca-93ac-1a7523692c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_features(nn.Module):\n",
    "    '''\n",
    "    the convolutional layers of ResNet\n",
    "    the average pooling and final fully convolutional layer is removed\n",
    "    '''\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False, filter=None, filter_layer=None):\n",
    "        \"\"\"\n",
    "        Initialize ResNet_features.\n",
    "\n",
    "        Args:\n",
    "            block: The residual block type\n",
    "            layers: Number of blocks in each layer\n",
    "            num_classes: Number of classes for classification.\n",
    "            zero_init_residual: Whether to zero-initialize residual batch norm weights.\n",
    "            filter: Custom filter.\n",
    "            filter_layer: Custom filter layer.\n",
    "        \"\"\"\n",
    "        super(ResNet_features, self).__init__()\n",
    "        self.inplanes = 64\n",
    "\n",
    "        # comes from the first conv and the following max pool\n",
    "        self.strides = [2, 2]\n",
    "        self.paddings = [3, 1]\n",
    "        self.kernel_sizes = [7, 3]\n",
    "\n",
    "        # Initial convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # Max pooling\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # Global average pooling\n",
    "        self.global_pool = nn.AvgPool2d(kernel_size=7)\n",
    "\n",
    "        # Define the sequential layers using residual blocks\n",
    "        self.block = block\n",
    "        self.layers = layers\n",
    "\n",
    "        \n",
    "\n",
    "        # Layer 1\n",
    "        self.layer1 = self._make_layer(block=block, planes=64, num_blocks=self.layers[0])\n",
    "        self.dn_layer1 = None\n",
    "        \n",
    "        # Layer 2\n",
    "        self.layer2 = self._make_layer(block=block, planes=128, num_blocks=self.layers[1], stride=2)\n",
    "        self.dn_layer2 = None\n",
    "\n",
    "        # Layer 3\n",
    "        self.layer3 = self._make_layer(block=block, planes=256, num_blocks=self.layers[2], stride=2)\n",
    "        self.dn_layer3 = None\n",
    "\n",
    "        # Layer 4\n",
    "        self.layer4 = self._make_layer(block=block, planes=512, num_blocks=self.layers[3], stride=2)\n",
    "        self.dn_layer4 = None\n",
    "\n",
    "         # Final fully connected layer\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "        # initialize the weights\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(layer, nn.BatchNorm2d):\n",
    "                nn.init.constant_(layer.weight, 1)\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        if zero_init_residual:\n",
    "            for layer in self.modules():\n",
    "                nn.init.constant_(layer.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride=1):\n",
    "        \"\"\"\n",
    "        Create a sequential layer consisting of multiple residual blocks.\n",
    "\n",
    "        Args:\n",
    "            block: The block type.\n",
    "            planes : Number of output channels for the blocks.\n",
    "            num_blocks: Number of blocks in the layer.\n",
    "            stride: Stride for the first block. \n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: A sequence of residual blocks.\n",
    "        \"\"\"\n",
    "        downsample = None\n",
    "        # Downsample for dimension matching when stride > 1 or channel mismatch\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "          # First block with optional downsampling\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        \n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        #  Track kernel, stride, and padding info\n",
    "        for each_block in layers:\n",
    "            block_kernel_sizes, block_strides, block_paddings = each_block.block_conv_info()\n",
    "            self.kernel_sizes.extend(block_kernel_sizes)\n",
    "            self.strides.extend(block_strides)\n",
    "            self.paddings.extend(block_paddings)\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Standard forward pass through the network.\n",
    "        \"\"\"\n",
    "        inputs = self.conv1(inputs)\n",
    "        inputs = self.bn1(inputs)\n",
    "        inputs = self.relu(inputs)\n",
    "        inputs = self.maxpool(inputs)\n",
    "\n",
    "        inputs = self.layer1(inputs)\n",
    "\n",
    "        if self.dn_layer1 is not None:\n",
    "            inputs = self.dn_layer1(inputs)\n",
    "        inputs = self.layer2(inputs)\n",
    "        if self.dn_layer2 is not None:\n",
    "            inputs = self.dn_layer2(inputs)\n",
    "        inputs = self.layer3(inputs)\n",
    "        if self.dn_layer3 is not None:\n",
    "            inputs = self.dn_layer3(inputs)\n",
    "        inputs = self.layer4(inputs)\n",
    "        if self.dn_layer4 is not None:\n",
    "            inputs = self.dn_layer4(inputs)\n",
    "        inputs = self.global_pool(inputs)\n",
    "        inputs = inputs.reshape(-1, 512)\n",
    "\n",
    "        output = self.fc(inputs)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e814502-a1af-440a-881b-effae3d26c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_18(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNet_features(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11d6c6-536d-409d-b3c4-93d45cb0dff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cb4e7-c9b1-49e2-8099-c57343de50b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
